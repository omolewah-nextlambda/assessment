{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 Assessment \n",
    "\n",
    "Welcome to your Module 5 Assessment. You will be tested for your understanding of concepts and ability to programmatically solve problems that have been covered in class and in the curriculum. \n",
    "\n",
    "**_Read the instructions very carefully!_** You will be asked both to write code and respond to a few short answer questions.  \n",
    "\n",
    "The goal here is to demonstrate your knowledge. Showing that you know things about certain concepts and how to apply different methods is more important than getting the best model.\n",
    "\n",
    "The sections of the assessment are:\n",
    "\n",
    "- Decision Trees\n",
    "- Ensemble Models \n",
    "- PCA\n",
    "- Clustering\n",
    "\n",
    "**Note on the short answer questions**: \n",
    "> Please use your own words, even if you consult another source to help you craft your response. Short answer questions are not necessarily being assessed on grammatical correctness or sentence structure, but do your best to communicate your answers clearly!\n",
    "\n",
    "\n",
    "## Decision Trees [Suggested Time: 15 min]\n",
    "\n",
    "### Concepts \n",
    "You're given a dataset of **30** elements, 15 of which belong to a positive class (denoted by *`+`* ) and 15 of which do not (denoted by `-`). These elements are described by two attributes, A and B, that can each have either one of two values, true or false. \n",
    "\n",
    "The diagrams below show the result of splitting the dataset by attribute: the diagram on the left hand side shows that if we split by Attribute A there are 13 items of the positive class and 2 of the negative class in one branch and 2 of the positive and 13 of the negative in the other branch. The right hand side shows that if we split the data by Attribute B there are 8 items of the positive class and 7 of the negative class in one branch and 7 of the positive and 8 of the negative in the other branch.\n",
    "\n",
    "<img src=\"images/decision_stump.png\">\n",
    "\n",
    "**1.1) Which one of the two attributes resulted in the best split of the original data? How do you select the best attribute to split a tree at each node?** _(Hint: Mention splitting criteria)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here \n",
    "Attribute A because the split on this feature results in the largest information gain (IG) for any given criterion (gini or entropy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees for Regression \n",
    "\n",
    "In this section, you will use decision trees to fit a regression model to the Combined Cycle Power Plant dataset. \n",
    "\n",
    "This dataset is from the UCI ML Dataset Repository, and has been included in the `data` folder of this repository as an Excel `.xlsx` file, `Folds5x2_pp.xlsx`. \n",
    "\n",
    "The features of this dataset consist of hourly average ambient variables taken from various sensors located around a power plant that record the ambient variables every second.  \n",
    "- Temperature (AT) \n",
    "- Ambient Pressure (AP) \n",
    "- Relative Humidity (RH)\n",
    "- Exhaust Vacuum (V) \n",
    "\n",
    "The target to predict is the net hourly electrical energy output (PE). \n",
    "\n",
    "The features and target variables are not normalized.\n",
    "\n",
    "In the cells below, we import `pandas` and `numpy` for you, and we load the data into a pandas DataFrame. We also include code to inspect the first five rows and get the shape of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Load the data\n",
    "filename = 'data/Folds5x2_pp.xlsx'\n",
    "df = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first five rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9568, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the dataframe \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting any models, you need to create training and testing splits for the data.\n",
    "\n",
    "Below, we split the data into features and target ('PE') for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['PE'])]\n",
    "y = df['PE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2) Split the data into training and test sets. Create training and test sets with `test_size=0.5` and `random_state=1`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. Replace None with appropriate code. \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3) Fit a vanilla decision tree regression model with scikit-learn to the training data.** Set `random_state = 1` for reproducibility. **Evaluate the model on the test data.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor(max_depth=3)\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4) Obtain the mean squared error, mean absolute error, and coefficient of determination (r2 score) of the predictions on the test set.** _Hint: Look at the `sklearn.metrics` module._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 26.61989753408775\n",
      "Mean Absolute Error: 4.018921825303308\n",
      "R-squared: 0.9101796947792778\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Replace None with appropriate code. \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = tree_reg.predict(X_test) \n",
    "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: MSE = 22.21041691053512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of Decision Trees for Regression\n",
    "\n",
    "For this next section feel free to refer to the scikit learn documentation on [decision tree regressors](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5) Add hyperparameters to a a new decision tree and fit it to our training data and evaluate the model with the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=2,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here  ---- Increase the max depth and minimum sample leaf changed to 2\n",
    "tree_reg = DecisionTreeRegressor(max_depth=5, min_samples_leaf=2)\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6) Obtain the mean squared error, mean absolute error, and coefficient of determination (r2 score) of the predictions on the test set. Did this improve your previous model? (It's ok if it didn't)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 19.71735594937567\n",
      "Mean Absolute Error: 3.3999398652759756\n",
      "R-squared: 0.9334701071914085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = tree_reg.predict(X_test) \n",
    "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your answer and explanation here\n",
    "The model improved. The Mean Squared Error reduced by approximately 77 percent, the Mean Absolute Error decreased approximately 85 percent and the R-Squared increased from 91 percent to 93 percent. Which means the new model can explain 93 percent of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods [Suggested Time: 20 min]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Ensemble Methods\n",
    "\n",
    "**2.1) Explain how the random forest algorithm works. Why are random forests resilient to overfitting?**\n",
    "\n",
    "_Hint: Your answer should discuss bagging and the subspace sampling method._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here\n",
    "Random forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests and Hyperparameter Tuning using GridSearchCV\n",
    "\n",
    "In this section, you will perform hyperparameter tuning for a Random Forest classifier using GridSearchCV. You will use `scikit-learn`'s wine dataset to classify wines into one of three different classes. \n",
    "\n",
    "After finding the best estimator, you will interpret the best model's feature importances. \n",
    "\n",
    "In the cells below, we have loaded the relevant imports and the wine data for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports \n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the data \n",
    "wine = load_wine()\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X = pd.DataFrame(X, columns=wine.feature_names)\n",
    "y = pd.Series(y)\n",
    "y.name = 'target'\n",
    "df = pd.concat([X, y.to_frame()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, we inspect the first five rows of the dataframe and compute the dataframe's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also get descriptive statistics for the dataset features, and obtain the distribution of classes in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
       "count       178.000000  178.000000                    178.000000   178.000000  \n",
       "mean          5.058090    0.957449                      2.611685   746.893258  \n",
       "std           2.318286    0.228572                      0.709990   314.907474  \n",
       "min           1.280000    0.480000                      1.270000   278.000000  \n",
       "25%           3.220000    0.782500                      1.937500   500.500000  \n",
       "50%           4.690000    0.965000                      2.780000   673.500000  \n",
       "75%           6.200000    1.120000                      3.170000   985.000000  \n",
       "max          13.000000    1.710000                      4.000000  1680.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    59\n",
       "1    71\n",
       "2    48\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now perform hyper-parameter tuning for a Random Forest classifier.\n",
    "\n",
    "**2.2) Construct a `param_grid` dictionary to pass to `GridSearchCV` when instantiating the object. Choose at least 3 hyper-parameters to tune and 3 values for each.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with relevant code \n",
    "param_grid = [{'n_estimators': [4,6,7,10], 'max_features': [2, 4, 6, 8],  'max_leaf_nodes':[5,10,15,20],'class_weight':['balanced']},]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the `param_grid` dictionary of hyperparameters, let's continue performing hyperparameter optimization of a Random Forest Classifier. \n",
    "\n",
    "In the cell below, we include the relevant imports for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3) Create an instance of a Random Forest classifier estimator; call it `rfc`.** Make sure to set `random_state=42` for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "rfc = RandomForestClassifier(random_state=42) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4) Create an instance of an `GridSearchCV` object and fit it to the data.** Call the instance `cv_rfc`. \n",
    "\n",
    "* Use the random forest classification estimator you instantiated in the cell above, the parameter grid dictionary constructed, and make sure to perform 5-fold cross validation. \n",
    "* The fitting process should take 10 - 15 seconds to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adara\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'class_weight': ['balanced'],\n",
       "                          'max_features': [2, 4, 6, 8],\n",
       "                          'max_leaf_nodes': [5, 10, 15, 20],\n",
       "                          'n_estimators': [4, 6, 7, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None with appropriate code \n",
    "cv_rfc = GridSearchCV(rfc, param_grid, cv=5,scoring=None,return_train_score=True) \n",
    "cv_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5) What are the best training parameters found by GridSearchCV?** \n",
    "\n",
    "_Hint: Explore the documentation for GridSearchCV._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'max_features': 2,\n",
       " 'max_leaf_nodes': 10,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None with appropriate code \n",
    "cv_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we create a variable `best_model` that holds the best model found by the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cv_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we give you a function that creates a horizontal bar plot to visualize the feature importances of a model, sorted in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "def create_plot_of_feature_importances(model, X):\n",
    "    ''' \n",
    "    Inputs: \n",
    "    \n",
    "    model: A trained ensemble model instance\n",
    "    X: a dataframe of the features used to train the model\n",
    "    '''\n",
    "    \n",
    "    feat_importances = model.feature_importances_\n",
    "\n",
    "    features_and_importances = zip(X.columns, feat_importances)\n",
    "    features_and_importances = sorted(features_and_importances, \n",
    "                                     key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    features = [i[0] for i in features_and_importances]\n",
    "    importances = [i[1] for i in features_and_importances]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, importances)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Feature Importances')\n",
    "    plt.xlabel('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6) Create a plot of the best model's feature importances.** \n",
    "\n",
    "_Hint: To create the plot, pass the appropriate parameters to the function above._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here.\n",
    "create_plot_of_feature_importances(best_model, X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7) What are this model's top 3 features in order of descending importance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here \n",
    "1. flavanoids\n",
    "2. od280/od315_of_diluted_wines\n",
    "3. color_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Components Analysis [Suggested Time: 20 min]\n",
    "\n",
    "### Training a model with PCA-extracted features\n",
    "\n",
    "In this section, you'll apply the unsupervised learning technique of Principal Components Analysis to the wine dataset. \n",
    "\n",
    "You'll use the principal components of the dataset as features in a machine learning model. You'll use the extracted features to train a vanilla Random Forest Classifier, and compare model performance to a model trained without PCA-extracted features. \n",
    "\n",
    "In the cell below, we import the data for you, and we split the data into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(X, columns=wine.feature_names)\n",
    "y = pd.Series(y)\n",
    "y.name = 'class'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1) Fit PCA to the training data.** \n",
    "\n",
    "Call the PCA instance you'll create `wine_pca`. Set `n_components=0.9` and make sure to use `random_state = 42`.\n",
    "\n",
    "_Hint: Make sure to include necessary imports for **preprocessing the data!**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "wine_pca = PCA(n_components=0.9, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2) How many principal components are there in the fitted PCA object?**\n",
    "\n",
    "_Hint: Look at the list of attributes of trained `PCA` objects in the scikit-learn documentation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# Replace None with appropriate code \n",
    "print(len(wine_pca.components_.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: you should end up with 8 components.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll reduce the dimensionality of the training data to the number of components that explain at least 90% of the variance in the data, and then you'll use this transformed data to fit a Random Forest classification model. \n",
    "\n",
    "You'll compare the performance of the model trained on the PCA-extracted features to the performance of a model trained using all features without feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3) Transform the training features into an array of reduced dimensionality using the `wine_pca` PCA object you've fit in the previous cell.** Call this array `X_train_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code  \n",
    "X_train_pca = wine_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a dataframe from this array of transformed features and we inspect the first five rows of the dataframe for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-157.493066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.581595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.460491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.908813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-447.424342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0 -157.493066\n",
       "1  -65.581595\n",
       "2   13.460491\n",
       "3  142.908813\n",
       "4 -447.424342"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from this array of transformed features \n",
    "X_train_pca = pd.DataFrame(X_train_pca)\n",
    "\n",
    "# Inspect the first five rows of the transformed features dataset \n",
    "X_train_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will now use the PCA-extracted features to train a random forest classification model.\n",
    "\n",
    "**3.4) Instantiate a vanilla Random Forest Classifier (call it `rfc`) and fit it to the transformed training data.** Set `random_state = 42`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=16, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5) Evaluate model performance on the test data and place model predictions in a variable called `y_pca_pred`.**\n",
    "\n",
    "_Hint: Make sure to transform the test data the same way as you transformed the training data!!!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "y_pca_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we print the classification report for the model performance on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        21\n",
      "           2       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pca_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to fit a vanilla Random Forest Classifier to the untransformed training data,  evaluate its performance on the untransformed test data, and print the classification report for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        19\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.93      0.93      0.93        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adara\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vanilla_rfc = RandomForestClassifier(random_state=42)\n",
    "vanilla_rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = vanilla_rfc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6) Compare model performance. Did the overall accuracy of the model improve when using the transformed features?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your answer here \n",
    "The performance of the model increased using the transformed features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering [Suggested Time: 30 min]\n",
    "\n",
    "### Clustering Algorithms: k-means and hierarchical agglomerative clustering\n",
    "\n",
    "#### 4.1) Using the gif below for reference, describe the steps of the k-means clustering algorithm.\n",
    "* If the gif doesn't run, you may access it via [this link](images/centroid.gif).\n",
    "\n",
    "<img src='images/centroid.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your answer here\n",
    "Randomly pick a set of group representatives. Assign all of the items to the nearest representative. Update the group representative to more accurately represent its members. Revisit all of the items, assigning them to their nearest group representative. Then repeat the steps until the loss metric is smallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2) In a similar way, describe the process behind Hierarchical Agglomerative Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your answer here\n",
    "Hierarchical Agglomerative clustering works in a “bottom-up” procedure. Each object is initially considered as a single-element cluster (leaf). At each step of the algorithm, the two clusters that are the most similar are combined into a new bigger cluster (nodes). This procedure is iterated until all points are member of just one single big cluster (root) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means Clustering\n",
    "\n",
    "For this question, you will apply k-means clustering to your now friend, the wine dataset. \n",
    "\n",
    "You will use scikit-learn to fit k-means clustering models, and you will determine the optimal number of clusters to use by looking at silhouette scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the wine dataset for you in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(X, columns = wine.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3) Write a function called `get_labels` that will find `k` clusters in a dataset of features `X`, and return the labels for each row of `X`.**\n",
    "\n",
    "_Hint: Within the function, you'll need to:_\n",
    "* instantiate a k-means clustering model (use `random_state = 1` for reproducibility),\n",
    "* fit the model to the data, and\n",
    "* return the labels for each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Replace None and pass with appropriate code\n",
    "def get_labels(k, X):\n",
    "    \n",
    "    # Instantiate a k-means clustering model with random_state=1 and n_clusters=k\n",
    "    kmeans = KMeans(n_clusters=k, \n",
    "            init='random', \n",
    "            n_init=10, \n",
    "            max_iter=300,\n",
    "            tol=1e-04,\n",
    "            random_state=1)\n",
    "    \n",
    "    # Fit the model to the data\n",
    "    y_pred = kmeans.fit_predict(X)\n",
    "    \n",
    "    # return the predicted labels for each row in the data\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4) Fit the k-means algorithm to the wine data for k values in the range 2 to 9 using the function you've written above. Obtain the silhouette scores for each trained k-means clustering model, and place the values in a list called `silhouette_scores`.** \n",
    "\n",
    "We have provided you with some starter code in the cell below.\n",
    "\n",
    "_Hints: What imports do you need? Do you need to pre-process the data in any way before fitting the k-means clustering algorithm?_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "silhouette_scores= []\n",
    "\n",
    "for k in range(2, 10):\n",
    "    labels = get_labels(k, X) \n",
    "    \n",
    "    score = silhouette_score(X, labels, metric='euclidean')\n",
    "    \n",
    "    silhouette_scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to plot the silhouette scores obtained for each different value of k against k, the number of clusters we asked the algorithm to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'silhouette score')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.title('Silhouette scores vs number of clusters')\n",
    "plt.xlabel('k (number of clusters)')\n",
    "plt.ylabel('silhouette score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.5) Which value of k would you choose based on the plot of silhouette scores? How does this number compare to the number of classes in the wine dataset?**\n",
    "\n",
    "Hint: this number should be <= 5.  If it's not, check your answer in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here \n",
    "k = 2 because, at k = 2, indicate that the sample is far away from the neighboring clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
